{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5d155e-805b-4d69-b519-e93e80a96146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import csv\n",
    "import librosa\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00c72c4-6daa-47b5-9bfc-587ab3ab4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/courses/EDS232/rainforest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4751ac5-228d-490b-9429-ac9430298017",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft = 2048\n",
    "hop = 512\n",
    "# Less rounding errors this way\n",
    "sr = 48000\n",
    "length = 10 * sr\n",
    "\n",
    "with open('/courses/EDS232/rainforest/train_tp.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "\n",
    "# data = pd.read_csv(os.path.join(base_dir, 'train_tp.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9cd9cd0-46d0-4b15-9f4b-04fe1bbb5196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum frequency: 84, maximum frequency: 15056\n"
     ]
    }
   ],
   "source": [
    "# Check minimum/maximum frequencies for bird calls\n",
    "# Not neccesary, but there are usually plenty of noise in low frequencies, and removing it helps\n",
    "fmin = 24000\n",
    "fmax = 0\n",
    "\n",
    "\n",
    "# Skip header row (recording_id,species_id,songtype_id,t_min,f_min,t_max,f_max) and start from 1 instead of 0\n",
    "for i in range(1, len(data)):\n",
    "    if fmin > float(data[i][4]):\n",
    "        fmin = float(data[i][4])\n",
    "    if fmax < float(data[i][6]):\n",
    "        fmax = float(data[i][6])\n",
    "\n",
    "# Get some safety margin\n",
    "fmin = int(fmin * 0.9)\n",
    "\n",
    "fmax = int(fmax * 1.1)\n",
    "print('Minimum frequency: ' + str(fmin) + ', maximum frequency: ' + str(fmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb12b0-9ebd-480c-adb4-4157434ae6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting spectrogram generation\n",
      "Processed 100 train examples from 1217\n",
      "Processed 200 train examples from 1217\n",
      "Processed 300 train examples from 1217\n",
      "Processed 400 train examples from 1217\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Starting spectrogram generation')\n",
    "for i in range(1, len(data)):\n",
    "    # All sound files are 48000 bitrate, no need to slowly resample\n",
    "    wav, sr = librosa.load('/courses/EDS232/rainforest/train/' + data[i][0] + '.flac', sr=None)\n",
    "    \n",
    "    t_min = float(data[i][3]) * sr\n",
    "    t_max = float(data[i][5]) * sr\n",
    "    \n",
    "    # Positioning sound slice\n",
    "    center = np.round((t_min + t_max) / 2)\n",
    "    beginning = center - length / 2\n",
    "    if beginning < 0:\n",
    "        beginning = 0\n",
    "    \n",
    "    ending = beginning + length\n",
    "    if ending > len(wav):\n",
    "        ending = len(wav)\n",
    "        beginning = ending - length\n",
    "        \n",
    "    slice = wav[int(beginning):int(ending)]\n",
    "    \n",
    "    # Mel spectrogram generation\n",
    "    # Default settings were bad, parameters are adjusted to generate somewhat \n",
    "    # reasonable quality images\n",
    "    # The better your images are, the better your neural net would perform\n",
    "    # You can also use librosa.stft + librosa.amplitude_to_db instead\n",
    "    mel_spec = librosa.feature.melspectrogram(slice, n_fft=fft, hop_length=hop, sr=sr, fmin=fmin, fmax=fmax, power=1.5)\n",
    "    mel_spec = resize(mel_spec, (224, 400))\n",
    "    \n",
    "    # Normalize to 0...1 - this is what goes into neural net\n",
    "    mel_spec = mel_spec - np.min(mel_spec)\n",
    "    mel_spec = mel_spec / np.max(mel_spec)\n",
    "\n",
    "    # And this 0...255 is for the saving in bmp format\n",
    "    mel_spec = mel_spec * 255\n",
    "    mel_spec = np.round(mel_spec)    \n",
    "    mel_spec = mel_spec.astype('uint8')\n",
    "    mel_spec = np.asarray(mel_spec)\n",
    "    \n",
    "    bmp = Image.fromarray(mel_spec, 'L')\n",
    "    bmp.save('/courses/EDS232/rainforest/working/' + data[i][0] + '_' + data[i][1] + '_' + str(center) + '.bmp')\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print('Processed ' + str(i) + ' train examples from ' + str(len(data)))\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067567c-7a89-40d2-b6c2-0fcf47728c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_birds = 24\n",
    "# 6GB GPU-friendly (~4 GB used by model)\n",
    "# Increase if neccesary\n",
    "batch_size = 16\n",
    "\n",
    "# This is enough to exactly reproduce results on local machine (Windows / Turing GPU)\n",
    "# Kaggle GPU kernels (Linux / Pascal GPU) are not deterministic even with random seeds set\n",
    "# Your score might vary a lot (~up to 0.05) on a different runs \n",
    "# due to picking different epochs to submit\n",
    "rng_seed = 1234\n",
    "random.seed(rng_seed)\n",
    "np.random.seed(rng_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(rng_seed)\n",
    "torch.manual_seed(rng_seed)\n",
    "torch.cuda.manual_seed(rng_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552bb4c-ca2d-4c1c-8f7c-4cae15e1aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as torchdata\n",
    "\n",
    "class RainforestDataset(torchdata.Dataset):\n",
    "    def __init__(self, filelist):\n",
    "        self.specs = []\n",
    "        self.labels = []\n",
    "        for f in filelist:\n",
    "            # Easier to pass species in filename at the start; \n",
    "            # worth changing later to more capable method\n",
    "            label = int(str.split(f, '_')[1])\n",
    "            label_array = np.zeros(num_birds, dtype=np.single)\n",
    "            label_array[label] = 1.\n",
    "            self.labels.append(label_array)\n",
    "            \n",
    "            # Open and save spectrogram to memory\n",
    "            \n",
    "            # If you use more spectrograms (add train_fp, for example), \n",
    "            # then they would not all fit to memory\n",
    "            # In this case you should load them on the fly in __getitem__\n",
    "            img = Image.open('/courses/EDS232/rainforest/working/' + f)\n",
    "            mel_spec = np.array(img)\n",
    "            img.close()\n",
    "            \n",
    "            # Transforming spectrogram from bmp to 0..1 array\n",
    "            mel_spec = mel_spec / 255\n",
    "            # Stacking for 3-channel image for resnet\n",
    "            mel_spec = np.stack((mel_spec, mel_spec, mel_spec))\n",
    "            \n",
    "            self.specs.append(mel_spec)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.specs)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        # Augment here if you want\n",
    "        return self.specs[item], self.labels[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8d92e-f7bb-41f1-a66c-8419d59c4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "label_list = []\n",
    "\n",
    "for f in os.listdir('/courses/EDS232/rainforest/working/'):\n",
    "    if '.bmp' in f:\n",
    "        file_list.append(f)\n",
    "        label = str.split(f, '_')[1]\n",
    "        label_list.append(label)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=rng_seed)\n",
    "\n",
    "train_files = []\n",
    "val_files = []\n",
    "\n",
    "for fold_id, (train_index, val_index) in enumerate(skf.split(file_list, label_list)):\n",
    "    # Picking only first fold to train/val on\n",
    "    # This means loss of 20% training data\n",
    "    # To avoid this, you can train 5 different models on 5 folds and average predictions\n",
    "    if fold_id == 0:\n",
    "        train_files = np.take(file_list, train_index)\n",
    "        val_files = np.take(file_list, val_index)\n",
    "\n",
    "print('Training on ' + str(len(train_files)) + ' examples')\n",
    "print('Validating on ' + str(len(val_files)) + ' examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1879e146-da84-4271-8bbc-7651a9c76b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install resnest > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f01b5b-9f21-4dcc-8ec6-06af0d939aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from resnest.torch import resnest50\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f5a41-f53d-4e2c-9386-b27dedd58953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412c7ef-0f68-43a8-8eab-b747a6320091",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RainforestDataset(train_files)\n",
    "val_dataset = RainforestDataset(val_files)\n",
    "\n",
    "train_loader = torchdata.DataLoader(train_dataset, \n",
    "                                    batch_size=batch_size, \n",
    "                                    sampler=torchdata.RandomSampler(train_dataset))\n",
    "\n",
    "val_loader = torchdata.DataLoader(val_dataset, \n",
    "                                  batch_size=batch_size, \n",
    "                                  sampler=torchdata.RandomSampler(val_dataset))\n",
    "\n",
    "# ResNeSt: Split-Attention Networks\n",
    "# https://arxiv.org/abs/2004.08955\n",
    "# Significantly outperforms standard Resnet\n",
    "\n",
    "model = resnest50(pretrained=True)\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, num_birds)\n",
    ")\n",
    "\n",
    "# Picked for this notebook; pick new ones after major changes \n",
    "# (such as adding train_fp to train data)\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=0.01, \n",
    "                            weight_decay=0.0001, \n",
    "                            momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                            step_size=7, \n",
    "                                            gamma=0.4)\n",
    "\n",
    "# This loss function is not exactly suited for competition metric, \n",
    "# which only cares about ranking of predictions\n",
    "# Exploring different loss fuctions would be a good idea\n",
    "pos_weights = torch.ones(num_birds)\n",
    "pos_weights = pos_weights * num_birds\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    loss_function = loss_function.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a391f1b8-3a7e-4ba3-9f0d-d2a117375bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_corrects = 0\n",
    "\n",
    "# Train loop\n",
    "print('Starting training loop')\n",
    "for e in range(0, 40):\n",
    "    # Stats\n",
    "    train_loss = []\n",
    "    train_corr = []\n",
    "    \n",
    "    # Single epoch - train\n",
    "    model.train()\n",
    "    for batch, (data, target) in enumerate(train_loader):\n",
    "        data = data.float()\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Stats\n",
    "        vals, answers = torch.max(output, 1)\n",
    "        vals, targets = torch.max(target, 1)\n",
    "        corrects = 0\n",
    "        for i in range(0, len(answers)):\n",
    "            if answers[i] == targets[i]:\n",
    "                corrects = corrects + 1\n",
    "        train_corr.append(corrects)\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    # Stats\n",
    "    for g in optimizer.param_groups:\n",
    "        lr = g['lr']\n",
    "    print('Epoch ' + str(e) + ' training end. LR: ' + str(lr) + \n",
    "          ', Loss: ' + str(sum(train_loss) / len(train_loss)) +\n",
    "          ', Correct answers: ' + str(sum(train_corr)) + '/' + \n",
    "          str(train_dataset.__len__()))\n",
    "    \n",
    "    # Single epoch - validation\n",
    "    with torch.no_grad():\n",
    "        # Stats\n",
    "        val_loss = []\n",
    "        val_corr = []\n",
    "        \n",
    "        model.eval()\n",
    "        for batch, (data, target) in enumerate(val_loader):\n",
    "            data = data.float()\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = loss_function(output, target)\n",
    "            \n",
    "            # Stats\n",
    "            vals, answers = torch.max(output, 1)\n",
    "            vals, targets = torch.max(target, 1)\n",
    "            corrects = 0\n",
    "            for i in range(0, len(answers)):\n",
    "                if answers[i] == targets[i]:\n",
    "                    corrects = corrects + 1\n",
    "            val_corr.append(corrects)\n",
    "        \n",
    "            val_loss.append(loss.item())\n",
    "    \n",
    "    # Stats\n",
    "    print('Epoch ' + str(e) + ' validation end. LR: ' + str(lr) + \n",
    "          ', Loss: ' + str(sum(val_loss) / len(val_loss)) +\n",
    "          ', Correct answers: ' + str(sum(val_corr)) + '/' + str(val_dataset.__len__()))\n",
    "    \n",
    "    # If this epoch is better than previous on validation, save model\n",
    "    # Validation loss is the more common metric, \n",
    "    # but in this case our loss is misaligned with competition metric, \n",
    "    # making accuracy a better metric\n",
    "    if sum(val_corr) > best_corrects:\n",
    "        print('Saving new best model at epoch ' + str(e) + ' (' + \n",
    "              str(sum(val_corr)) + '/' + str(val_dataset.__len__()) + ')')\n",
    "        torch.save(model, 'best_model.pt')\n",
    "        best_corrects = sum(val_corr)\n",
    "        \n",
    "    # Call every epoch\n",
    "    scheduler.step()\n",
    "\n",
    "# Free memory\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086c821-9621-4f97-b52c-f6a67dacff8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
